---
title: "Sampling from processes given by solutions of SPDEs driven by non-Gaussian noise"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{"Sampling from processes given by solutions of SPDEs driven by non-Gaussian noise"}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Gaussian processes in applied statistics

In modern applied statistics gaussian processes are ubiquitous. Gaussian processes indexed by 1d parameters can be found from time series with discrete time and with continuous time to regression models with depedent noise. Gaussian processes indexed by multidimensional parameters are widely used in geostatistics.

A common geostatistical model is given by
$$ Y_i = x(\mathbf{s}_i) + \varepsilon_i, \quad i=1,\ldots,N, \quad \varepsilon_i\sim N(0, \sigma^2),$$
$$x(\mathbf{s}) \sim GP\left(\sum_{k=1}^{n_b} b_k(\mathbf{s})w_k, c(\mathbf{s},\mathbf{s}')\right),$$
where $N$ is the number of spatial observations, $GP(m,c)$ stands for a Gaussian process with mean function $m$ and covariance function $c$, $n_b$ is the number of basis functions, $\{b_k(\cdot)\}_{k=1}^{n_b}$ are basis functions, $w_k$ are weights to be estimated and $c(\cdot,\cdot)$ is a covariance function.

A popular and flexible covariance function for random fields on $\mathbb{R}^d$ is the Matérn covariance function:
$$c(\mathbf{s}, \mathbf{s}') = \frac{\sigma^2}{\Gamma(\nu)2^{\nu-1}}(\kappa \|\mathbf{s}-\mathbf{s}'\|)^\nu K_\nu(\kappa\|\mathbf{s}-\mathbf{s}'\|),$$
where $\Gamma(\cdot)$ is the Gamma function, $K_\nu(\cdot)$ is the modified Bessel function of the second kind, $\nu>0$ controls the correlation range and $\sigma^2$ is the variance. Finally, $\nu>0$ determines the smoothness of the field.

Usually, the model parameters are estimated via maximum likelihood estimation.

The main drawback with this approach is that the computational time needed in order to perform statistical inference usually scales as $\mathcal{O}(N^3)$.


## The SPDE approach with Gaussian noise

It is well-known (Whittle, 1963) that a Gaussian process $u(\mathbf{s})$ with Matérn covariance function solves the stochastic partial differential equation (SPDE)
\begin{equation}\label{spde}
(\kappa^2 -\Delta)^\beta u = \mathcal{W}\quad \hbox{in } \mathcal{D},
\end{equation}
where $\Delta = \sum_{i=1}^d \frac{\partial^2}{\partial_{x_i^2}}$ is the Laplacian operator, $\mathcal{W}$ is the Gaussian spatial white noise on $\mathcal{D}=\mathbb{R}^d$, and $4\beta = 2\nu + d$.

Inspired by this relation between Gaussian processes with Matérn covariance functions and solutions of the above SPDE, [Lindgren et al. (2011)](https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.1467-9868.2011.00777.x) constructed computationally efficient Gaussian Markov random field approximations of $u(\mathbf{s})$, where the domain $\mathcal{D}\subsetneq \mathbb{R}^d$ is bounded and $2\beta\in\mathbb{N}$.

The approximate solutions of the SPDE are obtained through a finite element discretization.

### Finite element approximation

We will now provide a brief description of the finite element method they used. To make the description simpler we will consider the nonfractional SPDE given by
$$(\kappa^2 - \Delta) u(\mathbf{s}) = \mathcal{W}(\mathbf{s}),$$
on some bounded domain $\mathcal{D}$ in $\mathbb{R}^d$. The Laplacian operator is augmented with boundary conditions. Usually one considers Dirichlet, in which the process is zero on the boundary of $\mathcal{D}$, or Neumann, in which the directional derivarives of the process in the normal directions is zero on the boundary of $\mathcal{D}$.

The equation is interpreted in the following weak sense: for every function $\psi(\mathbf{s})$ from some suitable space of test functions, the following identity holds
$$\langle \psi, (\kappa^2-\Delta)u\rangle_{\mathcal{D}} \stackrel{d}{=} \langle \psi, \mathcal{W}\rangle_{\mathcal{D}},$$
where $\stackrel{d}{=}$ means equality in distribution and $\langle\cdot,\cdot\rangle_{\mathcal{D}}$ is the standard inner product in $L_2(\mathcal{D})$, $\langle f,g\rangle_{\mathcal{D}} = \int_\mathcal{D} f(\mathbf{s})g(\mathbf{s}) d\mathbf{s}.$

The finite element method (FEM) consists on considering a finite dimensional space of test functions $V_n$. In the Galerkin method, we consider $V_n = {\rm span}\{\varphi_1,\ldots,\varphi_n\}$, where $\varphi_i(\mathbf{s}), i=1,\ldots, n$ are piecewise linear basis functions obtained from a triangulation of $\mathcal{D}$.

Then, we write approximate the solution $u$ by $u_n$, where $u_n$ is written in terms of the basis functions as
$$u_n(\mathbf{s}) = \sum_{i=1}^n w_i \varphi_i(\mathbf{s}).$$
We thus obtain the system of linear equations
$$\left\langle \varphi_j, (\kappa^2 - \Delta)\left(\sum_{i=1}^n w_i\varphi_i\right)\right\rangle_{\mathcal{D}} \stackrel{d}{=} \langle \varphi_j, \mathcal{W}\rangle_{\mathcal{D}},\quad\hbox{for } j=1,\ldots,n.$$
We begin by handling the right-hand side of the above expression. At first, notice that
$$\langle \varphi_j, \mathcal{W}\rangle_{\mathcal{D}} = \int_{\mathcal{D}} \varphi_j(\mathbf{s})d\mathcal{W}(\mathbf{s}) \sim N\left(0, \int_{\mathcal{D}} \varphi_j^2(\mathbf{s})d\mathbf{s}\right),$$
since $\varphi_j$ is deterministic. Also, by using, again, the fact that $\varphi_j$ is deterministic, we have that
$$C\left(\int_{\mathcal{D}} \varphi_i(\mathbf{s}) d\mathcal{W}(\mathbf{s}), \int_{\mathcal{D}} \varphi_j(\mathbf{s}) d\mathcal{W}(\mathbf{s}) \right) = \int_{\mathcal{D}} \varphi_i(\mathbf{s})\varphi_j(\mathbf{s}) d\mathbf{s}.$$
This shows that
$$(\langle \varphi_1, \mathcal{W}\rangle_{\mathcal{D}}, \ldots, \langle \varphi_n, \mathcal{W}\rangle_{\mathcal{D}}) \sim N(0, \mathbf{C}),$$
where $\mathbf{C}$ is an $n\times n$ matrix with $(i,j)$th entry given by
$$\mathbf{C}_{i,j} = \int_{\mathcal{D}} \varphi_i(\mathbf{s})\varphi_j(\mathbf{s}) d\mathbf{s}.$$
The matrix $\mathbf{C}$ is known as the *mass matrix* in FEM theory.

Now let us handle the left hand side of the weak formulation of the SPDE. By using Green's first identity we obtain
$$
\begin{array}{ccl}
\left\langle \varphi_j, (\kappa^2 - \Delta)\left(\sum_{i=1}^n w_i\varphi_i\right)\right\rangle_{\mathcal{D}} &=& \sum_{i=1}^n \langle \varphi_j, (\kappa^2 - \Delta)w_i\varphi_i\rangle_{\mathcal{D}}\\
&=& \sum_{i=1}^n (\kappa^2 \langle \varphi_j, \varphi_i\rangle_{\mathcal{D}} + \langle \nabla \varphi_j, \nabla \varphi_i\rangle_{\mathcal{D}}) w_i, \quad j=1,\ldots, n,
\end{array}
$$
where the boundary terms vanish due to boundary conditions (for both Dirichlet and Neumann). We can then rewrite the last term in matrix form as
$$(\kappa^2 \mathbf{C} + \mathbf{G})\mathbf{w},$$
where $\mathbf{w} = (w_1,\ldots,w_n)$ and $\mathbf{G}$ is an $n\times n$ matrix with $(i,j)$th entry given by
$$\mathbf{G}_{i,j} = \int_{\mathcal{D}} \nabla \varphi_i(\mathbf{s})\nabla\varphi_j(\mathbf{s})d\mathbf{s}.$$
The matrix $\mathbf{G}$ is known in FEM theory as stiffness matrix.

Putting everything together, we have that
$$(\kappa^2 \mathbf{C} + \mathbf{G}) \mathbf{w} \sim N(0,\mathbf{C}).$$
Therefore, $\mathbf{w}$ is a centered Gaussian variable with precision matrix given by
$$\mathbf{Q} = (\kappa^2 \mathbf{C}+\mathbf{G})^\top \mathbf{C}^{-1}(\kappa^2 \mathbf{C}+\mathbf{G}).$$

### Computational advantages of the SPDE approach

For spatial problems, the computational cost usually scales as $\mathcal{O}(n^{3/2})$, where $n$ is the number of basis functions. This should be compared to the $\mathcal{O}(N^3)$ of the Gaussian random field approach.

This implies in accurate approximations which drastically reduces the computational cost for sampling and inference.

## Computing the finite-element matrices in *R*

Let us now compute the FEM matrices $\mathbf{C}$ and $\mathbf{G}$ in *R*.
We begin by considering the dataset *mcycle* from the *MASS* package. Specifically, we will consider a time series (so we will use FEM in one dimension) of measurements of head accelerations in a simulated motorcycle accident, used to test crash helmets. The data consists of two columns, *times* (in milliseconds after impact) and *accel* (in *g*).

```{r}
library(MASS)
data("mcycle")

head(mcycle)
```

Let us first consider the mesh induced by the data. To simplify things, let us sample 20 observations from the data.

```{r}
idx <- sample(1:nrow(mcycle),20)
mcycle_new <- mcycle[idx,]
loc <- mcycle_new$times
```

The mesh induced from the data is given in the figure below:

```{r, echo=FALSE , fig.width = 7, fig.height=2}
library(ggplot2)

ggplot(data.frame(loc), aes(x=loc, y=0)) +
  geom_point(size = 5)  +
  annotate("segment",x=min(loc),xend=max(loc), y=0, yend=0, size=2) +
  annotate("segment",x=min(loc),xend=min(loc), y=-0.1,yend=0.1, size=2) +
  annotate("segment",x=max(loc),xend=max(loc), y=-0.1,yend=0.1, size=2) +
  scale_x_continuous(limits = c(min(loc),max(loc))) +
  scale_y_continuous(limits = c(-1,1)) +
  scale_color_manual(values = unname(colours)) +
  theme(panel.background = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())
```

To compute the mass matrix $\mathbf{C}$ and the stiffness matrix $\mathbf{G}$ we can use the function *inla.mesh.1d* to generate the mesh and *inla.mesh.1d.fem* to compute the matrices $\mathbf{C}$ and $\mathbf{G}$:

```{r message=FALSE}
library(INLA)

mesh_loc <- inla.mesh.1d(loc)
fem_mesh_loc <- inla.mesh.1d.fem(mesh_loc)
C <- fem_mesh_loc$c1
G <- fem_mesh_loc$g1
head(C)
head(G)
```

Of course, we do not need to consider the mesh induced by the data. For instance, we could consider a mesh with equally spaced nodes. Let us consider with 10 nodes:

```{r}
loc_eq <- (max(loc) - min(loc))*0:9/9 + min(loc)
```

```{r, echo=FALSE , fig.width = 7, fig.height=2}
ggplot(data.frame(loc_eq), aes(x=loc_eq, y=0)) +
  geom_point(size = 5)  +
  annotate("segment",x=min(loc),xend=max(loc), y=0, yend=0, size=2) +
  annotate("segment",x=min(loc),xend=min(loc), y=-0.1,yend=0.1, size=2) +
  annotate("segment",x=max(loc),xend=max(loc), y=-0.1,yend=0.1, size=2) +
  scale_x_continuous(limits = c(min(loc),max(loc))) +
  scale_y_continuous(limits = c(-1,1)) +
  scale_color_manual(values = unname(colours)) +
  theme(panel.background = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())
```

We compute the matrices $\mathbf{C}$ and $\mathbf{G}$ by using the same functions as before:

```{r}
mesh_eq <- inla.mesh.1d(loc_eq)
fem_mesh_eq <- inla.mesh.1d.fem(mesh_eq)
C_eq <- fem_mesh_eq$c1
G_eq <- fem_mesh_eq$g1

head(C_eq)
head(G_eq)
```

### Examples in 2d

We will now provide an example of a two dimensional spatial data. To create a two dimensional mesh we will use the function *inla.mesh.2d*. We use this function to construct a [Constrained](https://en.wikipedia.org/wiki/Constrained_Delaunay_triangulation) [Refined](https://en.wikipedia.org/wiki/Delaunay_refinement) [Delaunay Triangulation](https://en.wikipedia.org/wiki/Delaunay_triangulation) on the domain of interest. We will provide some very brief examples without much details. The interested reader is referred to https://becarioprecario.bitbucket.io/spde-gitbook/ch-intro.html#sec:mesh for further details on the parameters of this function.

In order to create the mesh we need to pass some information about the domain. One way of doing this is, similar to the one dimensional case, to pass the locations of the nodes. These locations are passed in the *loc* argument. An alternative way of passing information about the domain is using the *loc.domain* argument. This argument allows one to provide a single polygon to determine the extent of the domain. When the nodes are passed via the *loc* argument, or the polygon is passed via the *loc.domain* argument, the algorithm will obtain a mesh for the convex hull induces by the nodes/polygon. Finally, in the last way to determine the region, one is able to provide a domain with non-convex boundary by providing a list of polygons to the *boundary* argument. Notice that for this case, each element of the list of polygons must be an element returned by the *inla.mesh.segment* function.

Once the region is specified in the function, one must also pass the *max.edge* argument. This argument provides the largest allowed triangle edge length from the triangulation. The *max.edge* argument should be given in the same scale as the coordinate data.

Another interesting argument to consider is the *offset* argument. This argument is used to extend the domain, making the boundary of the region farther away from the data. This is specially useful to avoid problems with the boundary conditions. For instance, the Dirichlet boundary conditions makes the variance of the process to be zero at the boundary, whereas the Neumann boundary condition makes the variance of the process twice as larger at the boundary. Both conditions may cause undesired behavior on the process. Therefore, by extending the domain, we are able to avoid those issues. A usual rule of thumb is to extend the region to twice the correlation range of the process.

Now, with respect to the details of the *offset* argument, it can be a number or a numeric vector with two components. If there is one number, it will create an inner extension of the boundary. The inner extension of the boundary considers a triangulation of the same "size"
as the original triangulation of the domain.
If one enters a two-dimensional vector, then the first coordinate is with respect to the inner extension and the second argument is with respect to the outer extension. The
triangulation on the outer extension is coarser than the triangulation in the inner extension.
If the number is positive, the extension will be done by considering that distance in the coordinates scale, and if the number is negative the extension will be done by a percentage of the region diameter. For instance, -0.1, will add an extension of 10\% of the region's diameter.

Let us consider the *SPDEtoy* dataset from *INLA* package. We will consider the first 30 observations.

We begin by considering a triangulation induced by the space locations. Thus, the boundary is given by the boundary of the convex hull of these points.

Below we provide a plot with the data.

```{r, fig.width=7, fig.height=5, cex=0.5}
data(SPDEtoy)

loc_2d <- SPDEtoy[1:30,c("s1","s2")]

plot(loc_2d, pch=1)
```

Now, we consider a plot with the triangulation. Based on the summary of the distances between the points from the dataset, we notice that our choice of *max.edge* will create small triangles.

```{r, fig.width=7, fig.height=5}
summary(dist(loc_2d))
mesh_2d_loc <- inla.mesh.2d(loc = loc_2d, max.edge = 0.2)

plot(mesh_2d_loc, draw.vertices = TRUE)
```

Now, to obtain the matrices $\mathbf{C}$ and $\mathbf{G}$ we proceed in the same manner as for the one dimensional case:

```{r}
fem_mesh_2d_loc <- inla.mesh.fem(mesh_2d_loc)

C_2d_loc <- fem_mesh_2d_loc$c1
print(C_2d_loc[1:6,1:6])

G_2d_loc <- fem_mesh_2d_loc$g1
print(G_2d_loc[1:6,1:6])
```

Let us now provide the boundary of the domain as the unit square polygon:

```{r, fig.width=7, fig.height=5}
square_pol <- cbind(c(0,0,1,1),c(0,1,0,1))

mesh_2d_loc_bd <- inla.mesh.2d(loc = loc_2d,
                            loc.domain = square_pol,
                            max.edge = 0.2)
plot(mesh_2d_loc_bd, draw.vertices = TRUE)
```

The finite element matrices are:

```{r}
fem_mesh_2d_loc_bd <- inla.mesh.fem(mesh_2d_loc_bd)

C_2d_loc_bd <- fem_mesh_2d_loc_bd$c1
print(C_2d_loc_bd[1:6,1:6])

G_2d_loc_bd <- fem_mesh_2d_loc_bd$g1
print(G_2d_loc_bd[1:6,1:6])
```

Finally, as in the one dimensional case, the mesh does not need to be induced from the data. So, let us create a triangulation based solely on the square polygon:

```{r, fig.width=7, fig.height=5}
mesh_2d_loc_dom <- inla.mesh.2d(loc.domain = square_pol,
                            max.edge = 0.2)
plot(mesh_2d_loc_dom, draw.vertices = TRUE)
```

The FEM matrices are:

```{r}
fem_mesh_2d_loc_dom <- inla.mesh.fem(mesh_2d_loc_dom)

C_2d_loc_dom <- fem_mesh_2d_loc_dom$c1
print(C_2d_loc_dom[1:6,1:6])

G_2d_loc_dom <- fem_mesh_2d_loc_dom$g1
print(G_2d_loc_dom[1:6,1:6])
```

Let us now provide some illustrations with the *offset* argument. Let us first
see an example of inner extension. Notice that the shape of the boundary is
approximately the same shape of the original region.

```{r, fig.width=7, fig.height=5}
mesh_2d_bd_off <- inla.mesh.2d(loc = loc_2d,
                            max.edge = 0.2,
                            offset = -0.5)
# With interior offset
plot(mesh_2d_bd_off, draw.vertices = TRUE)

#Without interior offset
plot(mesh_2d_loc, draw.vertices = TRUE)
```

We can readily compute its FEM matrices:

```{r}
fem_2d_bd_off <- inla.mesh.fem(mesh_2d_bd_off)

C_2d_bd_off <- fem_2d_bd_off$c1
print(C_2d_bd_off[1:6,1:6])

G_2d_bd_off <- fem_2d_bd_off$g1
print(G_2d_bd_off[1:6,1:6])
```

Now, let us consider a triangulation with inner and outer extensions. Notice that
the triangulation of the outer extension tends to be coarser than the triangulation
from the interior of the domain. Notice also that the shape of the boundary of the
outer extension heavily modified the shape of the original boundary of the domain.

```{r, fig.width=7, fig.height=5}
loc_2d_new <- SPDEtoy[,c("s1","s2")]
mesh_2d_bd_off2 <- inla.mesh.2d(loc = loc_2d_new,
                            max.edge = 1,
                            offset = c(-0.1,-0.2))
# With interior offset
plot(mesh_2d_bd_off2, draw.vertices = TRUE)
```


## The SPDE approach with non-Gaussian noise

Our goal now is to describe the SPDE approach when the noise is non-Gaussian.
The motivation for handling non-Gaussian noise comes from the fact that many features cannot not be handled by Gaussian noise. Some of these reasons are:

* Skewness;
* Heavier tails;
* Jumps in the sample paths;
* Asymmetries in the sample paths.

### Non-Gaussian Matérn fields

The idea is to replace the Gaussian white noise $\mathcal{W}$ in the SPDE by a non-Gaussian white noise $\dot{\mathcal{M}}$:
$$(\kappa^2 - \Delta)^\beta u = \dot{\mathcal{M}}.$$
The solution $u$ will have Matérn covariance function, but their marginal distributions will be non-Gaussian.

We want to apply the same idea to the non-Gaussian case, i.e., we want to consider the SPDE on a bounded domain $\mathcal{D}\subset\mathbb{R}^d$ and apply the finite element method.

Notice that the left-hand side of the equation did not change. Therefore, we should only take care of the right-hand side.

We will consider the same setup. More precisely, we consider $V_n = {\rm span}\{\varphi_1,\ldots,\varphi_n\}$, where $\varphi_i(\mathbf{s}), i=1,\ldots, n$ are piecewise linear basis functions obtained from a triangulation of $\mathcal{D}$ and we approximate the solution $u$ by $u_n$, where $u_n$ is written in terms of the basis functions as
$$u_n(\mathbf{s}) = \sum_{i=1}^n w_i \varphi_i(\mathbf{s}).$$
In the right-hand side we obtain a random vector
$$\mathbf{f} = (\dot{\mathcal{M}}(\varphi_1),\ldots, \dot{\mathcal{M}}(\varphi_n)),$$
where the functional $\dot{\mathcal{M}}$ is given by
$$\dot{\mathcal{M}}(\varphi_j) = \int_{\mathcal{D}} \varphi_j(\mathbf{s}) d\mathcal{M}(\mathbf{s}).$$
By considering $\mathcal{M}$ to be a type-G Lévy process, we obtain that $\mathbf{f}$ has a joint distribution that is easy to handle.

We say that a Lévy process is of type G if its increments can be represented as location-scale mixtures:
$$\gamma + \mu V + \sigma \sqrt{V}Z,$$
where $\gamma, \mu$ are parameters, $Z\sim N(0,1)$ and is independent of $V$, and $V$ is a positive infinitely divisible random variable.

Therefore, given a vector $\mathbf{V} = (V_1,\ldots,V_n)$ of independent stochastic variances (in our case, positive infinitely divisible random variables), we obtain that
$$\mathbf{f}|\mathbf{V} \sim N(\gamma + \mu\mathbf{V}, \sigma^2{\rm diag}(\mathbf{V})).$$
So, if we consider, for instance, the non-fractional and non-Gaussian SPDE
$$(\kappa^2 - \Delta) u = \dot{\mathcal{M}},$$
we obtain that the FEM weights $\mathbf{w} = (w_1,\ldots,w_n)$ satisfy
$$\mathbf{w}|\mathbf{V} \sim N(\mathbf{K}^{-1}(\gamma+\mu\mathbf{V}), \sigma^2\mathbf{K}^{-1}{\rm diag}(\mathbf{V})\mathbf{K}^{-1}),$$
where $\mathbf{K} = \kappa^2\mathbf{C}+\mathbf{G}$ is the discretization of the differential operator.

### The NIG model

We will delve into more details now by considering, as example, the NIG model.

First, we say that a random variable $V$ follows an inverse Gaussian distribution with parameters $\eta_1$ and $\eta_2$, denoted by $V\sim IG(\eta_1,\eta_2)$ if it has pdf given by
$$\pi(v) = \frac{\sqrt{\eta_2}}{\sqrt{2\pi v^3}} \exp\left\{-\frac{\eta_1}{2}v - \frac{\eta_2}{2v} + \sqrt{\eta_1\eta_2}\right\},\quad \eta_1,\eta_2>0.$$
We can generate samples of inverse Gaussian distributions with parameters $\eta_1$ and $\eta_2$ by generating samples from the [generalized inverse Gaussian distribution](https://en.wikipedia.org/wiki/Generalized_inverse_Gaussian_distribution) with parameters $p=-1/2$, $a=\eta_1$ and $b=\eta_2$. We can use the *rGIG* function to generate samples from the generalized inverse Gaussian distribution.

If $V\sim IG(\eta_1,\eta_2)$, then $X = \gamma +\mu V + \sigma \sqrt{V}Z$, with $Z\sim N(0,1)$, being independent of $V$, then $X$ follows a normal inverse Gaussian (NIG) distribution and has pdf
$$\pi(x) = \frac{e^{\sqrt{\eta_1\eta_2}+\mu(x-\gamma)/\sigma^2}\sqrt{\eta_2\mu^2/\sigma^2+\eta_1\eta_2}}{\pi\sqrt{\eta_2\sigma^2+(x-\gamma)^2}} K_1\left(\sqrt{(\eta_2\sigma^2+(x-\gamma)^2)(\mu^2/\sigma^4+\eta_1/\sigma^2)}\right),$$
where $K_1$ is a modified Bessel function of the third kind. In this form, the NIG density is overparameterized, and we therefore set $\eta_1=\eta_2=\eta$, which results in $E(V)=1$. Thus, one have the parameters, $\mu, \gamma$ and $\eta$.

The NIG model thus assumes that the stochastic variance $V_i$ follows an inverse Gaussian with parameters $\eta$ and $\eta h_i^2$, where $h_i = \int_{\mathcal{D}} \varphi_i(\mathbf{s}) d\mathbf{s}.$

Below, we see the plot of the densities of a NIG distribution for several choices of the parameters (we fix $\gamma=0$ and $\eta=1$):

```{r, echo=FALSE, message=FALSE, fig.width=7, fig.height=15}
library(ngme2)
library(plyr)
library(dplyr)
nig_df_fun <-  function(x, sigma, mu){
  data.frame(x = x, dnig = ngme2::dnig(x=x,
                                      delta=0,
                                      mu=mu, nu=1, sigma))
}
params <- expand.grid(sigma = c(1, 2, 4, 8), mu = c(-5,0,5))
nig_par <- mdply(params, nig_df_fun, x = seq(-20, 20, length=400))
nig_par <- nig_par %>% mutate(label = paste0("mu = ",mu))

ggplot(nig_par, mapping = aes(x = x, y=dnig, colour=factor(sigma)))+
  facet_wrap(~label,scales="free", nrow=3) +
  geom_line() +
  ylab("NIG density") + labs(colour = "sigma")
```


### Sampling from 1d NIG models

We will use the NIG model to illustrate how to sample from non-Gaussian SPDE models.

First, we will sample from an one dimensional NIG model. More precisely, we will consider the equation
$$(\kappa^2 - \partial^2/\partial t^2)u(t) = \dot{\mathcal{M}}(t).$$

We will take $\kappa=1$, $\sigma=1$, $\mu=-\gamma=0$, $\mathcal{D}=[0,100]$ and $\eta=0.5$. We will also consider a mesh with 1000 equally spaced nodes. Notice that for the NIG model we will also need the integral $\int_{\mathcal{D}}\varphi_i(\mathbf{s})d\mathbf{s}$. These values are returned by the element *c0* of the FEM list returned by *INLA*. In fact, *c0* is a diagonal matrix with diagonal entries given by these integrals.

```{r}
loc_nig_1d <- 0:999*(100/999)

mesh_loc_nig_1d <- inla.mesh.1d(loc_nig_1d)
fem_loc_nig_1d <- inla.mesh.1d.fem(mesh_loc_nig_1d)

C_nig_1d <- fem_loc_nig_1d$c1
G_nig_1d <- fem_loc_nig_1d$g1
h_nig_1d <- diag(fem_loc_nig_1d$c0)
```

Let us now build the matrix $K$, generate $V$ and then sample from the NIG model:
```{r, fig.width=7, fig.height=5}
K = C_nig_1d + G_nig_1d

n=length(h_nig_1d)

# Generating V from an inverse Gaussian distribution
#(a=eta, b = h^2*eta)

V = ngme2::rig(n, a = 0.5, b = h_nig_1d^2*0.5, sample.int(10^6, 1))
temp = rnorm(n, mean = 0, sd = sqrt(V))
W = solve(K, temp)
plot(loc_nig_1d, W, type="l")
```

### Sampling from 2d NIG models

We will now consider the 2d SPDE
$$(\kappa^2 - \partial^2/\partial x^2 - \partial^2/\partial y^2)u(x,y) = \dot{\mathcal{M}}(x,y).$$
We will take $\kappa=1$, $\sigma=1$, $\mu=-\gamma=0$, $\mathcal{D}=[0,10]^2$ and $\eta=0.5$. We will consider a triangulation obtained from 3362 points equally spaced inside the domain (based on a regular grid). Notice that, as in the 1d case, for the NIG model we will also need the integral $\int_{\mathcal{D}}\varphi_i(\mathbf{s})d\mathbf{s}$. These values are returned by the element *c0* of the FEM list returned by *INLA*.

```{r, fig.width=7, fig.height=5}
idx <- seq(0,10,0.25)
loc_2d_samp <- lapply(1:length(idx), function(i){cbind(idx[i],idx)})
loc_2d_samp <- do.call(rbind, loc_2d_samp)

plot(loc_2d_samp)

mesh_2d_samp <- inla.mesh.2d(loc = loc_2d_samp,
                            max.edge = 0.5)
plot(mesh_2d_samp)
```

Let us obtain the FEM matrices:

```{r}
fem_mesh_2d_samp <- inla.mesh.fem(mesh_2d_samp)

C_2d_samp <- fem_mesh_2d_samp$c1
G_2d_samp <- fem_mesh_2d_samp$g1
h_2d_samp <- diag(fem_mesh_2d_samp$c0)
```

Let us now build the matrix $K$, generate $V$ and then sample from the NIG model:
```{r, fig.width=7, fig.height=5}
K_2d = C_2d_samp + G_2d_samp

n_2d=length(h_2d_samp)

# Generating V from an inverse Gaussian distribution
#(a=eta, b = h^2*eta)

V_2d = ngme2::rig(n_2d, a = 0.5, b = h_2d_samp^2*0.5, seed  = sample.int(10^6, 1))
temp = rnorm(n_2d, mean = 0, sd = sqrt(V_2d))
W_2d = solve(K_2d, temp)

loc_2d_samp_idx <- mesh_2d_samp$idx$loc

df_samp <- data.frame(x = loc_2d_samp[,1], y = loc_2d_samp[,2],
                      w = as.vector(W_2d)[loc_2d_samp_idx])

ggplot(df_samp, aes(x=x,y=y)) +
  geom_raster(aes(fill=w), interpolate = TRUE) +
  scale_fill_gradientn(colours=c("blue","yellow"))
```

## References

* Lindgren, F., Rue, H., and Lindstrom, J. (2011). An explicit link between Gaussian fields and Gaussian Markov random fields: the stochastic partial differential equation approach. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 73(4):423–498.

* Whittle, P. (1963). Stochastic-processes in several dimensions. Bulletin of the International Statistical
Institute, 40(2):974–994.
