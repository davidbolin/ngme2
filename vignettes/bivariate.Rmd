---
title: "Bivariate models in Ngme2"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Bivariate models in Ngme2}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

For many applications, we need to deal with multivariate data. In this vignette, we will introduce the bivariate model which supports modeling two (non-Gaussian) fields and their correlation jointly. The main reference is Bolin and Wallin (2020) [Multivariate Type G Mat√©rn Stochastic Partial Differential Equation Random Fields](https://doi.org/10.1111/rssb.12351).

The `f` function specification is similar to ordinary model (See e.g. [Ngme2 AR(1) model](AR1-model.html)), but with two more fields to help identify the variables.
Extra arguments for the `f` are:

1. `group`: a vector of labels to indicate the group of different observations. For example, `group = c("field1", "field1", "field2", "field2", "field2)`.
If `group` is provided in `ngme()` function, no need to provide in `f()` function again.

2. `sub_models`: characters of length 2 with names equal to one of the labels in `group`, specifying the sub-models for the two fields. e.g. `sub_models=c(field1="rw1", field2="ar1")`.

We will see more examples in the following.

## Model structure

The bivariate model can model two fields $\mathbf{X}(s) = (X_1(s), X_2(s))$ jointly.
To model their correlation, we use dependence matrix $D(\theta, \rho)$ to correlate them (See Bolin and Wallin, 2020, section 2.2).

Remember that, for the univariate model, it can be written as:
$$ \mathcal{L} \mathbf{X}(s) = \mathcal{M},$$ where $\mathcal{L}$ is some operator, $\mathcal{M}$ represents the noise (Gaussian or non-Gaussian).

The bivariate model is similar, but with one more term to correlate the two fields:
$$ \mathbf{D(\theta, \rho)} diag(\mathcal{L_1}, \mathcal{L_2}) \mathbf{X}(s) = \mathcal{M},$$ where $\mathbf{D}$ is the dependence matrix. The noise can be classified into 4 types by their complexity, we will discuss them later.

The dependence matrix is defined as
$$
D(\theta, \rho) = \begin{pmatrix}
  \cos(\theta) + \rho \sin(\theta) & -\sin(\theta) \sqrt{1+\rho^2} \\
  \sin(\theta) - \rho \cos(\theta) & \cos(\theta) \sqrt{1+\rho^2}
\end{pmatrix},
$$
where $\theta \in [-\pi/4, \pi/4]$ and $\rho \in \mathbb{R}$. The $\theta$ controls the angle (rotation) of the bivariate model, and $\rho$ represents the cross-correlation between the two fields.

## One simple example

It's eaiser to understand with one exmaple. Say we have a time series model over 5 year from 2001 to 2005, with 2 fields *temperature* and *precipitation*. You want to model the two fields jointly. The data look like the following:

```{r toy-data, message=FALSE}
library(fmesher)
library(ngme2)

temp <- c(32, 33, 35.5, 36); year_temp <- c(2001, 2002, 2003, 2004)
precip <- c(0.1, 0.2, 0.5, 1, 0.2); year_pre <- c(2001, 2002, 2003, 2004, 2005)

# bind 2 fields in one vector, and make labels for them
y <- c(temp, precip); year <- c(year_temp, year_pre)
labels <- c(rep("temp", 4), rep("precip", 5)) # group is label for 2 fields

x1 <- 1:9
data <- data.frame(y, year, x1, labels)
data
```

Next we need to specify the model using `f()` function. Notice the way to specify 2 sub-models, and also 2 types of noises for each sub-model.

```{r toy-model}
# 1st way: simply put model types, using both c() and list() are ok
bv1 <- f(
  year, model = "bv",
  theta = pi / 8, rho = 0.5,
  sub_models = list(precip="ar1", temp="rw1"),
  group = labels, # can be inherited from ngme() function
  noise = list(
    precip=noise_normal(),
    temp=noise_normal()
  )
)
bv1

# 2nd way: allow more argument for sub_models
bv2 <- f(
  year, model = "bv",
  sub_models = list(
    precip=list(model="ar1", rho=0.5), # specify correlation parameter for ar1 model
    temp=list(model="rw1")
  ),
  group = labels,
  noise = list(
    precip=noise_normal(),
    temp=noise_nig() # can have 2 different noise for each field
  )
)
bv2
```

## Four increasing construction of noise

In bivariate models, we can have more detailed control over the noise of the model. The noise can be classified into 4 category (See Bolin and Wallin, 2020, section 3.1 for details):

- Type-G1: single mixing variable V, share V over 2 fileds.

- Type-G2: single V, different V for each field.

- Type-G3: general V, share V.

- Type-G4: general V, different V.

We can specify the type of noise by the following:

```{r type-G}
t1 <- f(
  year, model = "bv",
  sub_models = list(precip="ar1", temp="rw1"),
  group = labels,
  noise = list(
    precip=noise_normal(single_V=TRUE),
    temp=noise_normal(single_V=TRUE),
    share_V = TRUE
  )
)
t1

t2 <- f(
  year, model = "bv",
  sub_models = list(precip="ar1", temp="rw1"),
  group = labels,
  noise = list(
    precip=noise_normal(single_V=TRUE),
    temp=noise_normal(single_V=TRUE)
  )
)
t2

t3 <- f(
  year, model = "bv",
  sub_models = list(precip="ar1", temp="rw1"),
  group = labels,
  noise = list(
    precip=noise_normal(),
    temp=noise_normal(),
    share_V = TRUE
  )
)
t3

t4 <- f(
  year, model = "bv",
  sub_models = list(precip="ar1", temp="rw1"),
  group = labels,
  noise = list(
    precip=noise_normal(),
    temp=noise_normal()
  )
)
t4
```

## Interaction with other fields (e.g. fixed effects)

When it involves more than one field, things get complicated. When we have fixed effects but only for 1 field, we can use the special syntax `fe(<formula>, which_group=<group_name>)`. The argument `which_group` will tell which field we have fixed effects on. It works similar for modeling using `f()` function.

Here is one example, we have different fixed effects on different fields (Intercept for both fields, and *x1* for only *precip* field).

```{r fixed-effect, cache=TRUE}
m1 <- ngme(
  y ~ 0 + fe(~1, which_group = "temp") +
  fe(~1+x1, which_group = "precip") +
  f(year, model="rw1", which_group = "temp") +
  f(year,
    model = "bv",
    sub_models = list(precip="ar1", temp="rw1"),
    noise = list(
      precip = noise_nig(),
      temp = noise_nig()
    )
  ),
  data = data,
  group = data$labels,
  control_opt = control_opt(estimation = FALSE)
)
# examine the design matrix
m1$replicates[[1]]$X
```

## The correlated measurement noise

Now since we are taking measures of 2 different fields, there is some situation that we might want to assume the measurement of 2 fields have some correlation.

It can be written as $Y = X \beta + A W + \epsilon$, here $W$ is the bivariate model, and $\epsilon | V_{\epsilon} \sim N(0, \Sigma)$, $\Sigma_{i j} \neq 0$ if $Y_i$ and $Y_j$ are 2 different fields but measured at same location.

Now we need to modify the `family` argument in `ngme` function, we need to set `corr_measurement` and give the `index_corr` to indicate which observations are correlated.

We will see how to estimate it in the next example.

## Put it all together (Simulation + Estimation example)

In this example, we will first use `simulate` function to simulate the hidden bivariate process. Notice that we need to provide the labels for the 2 fields. Then we will generate the measurement noise $\epsilon$ with some correlation. Finally, we will use the `ngme` function to estimate the model.

```{r corr-measurement, cache=TRUE}
n_obs <- 2000
n_each <- n_obs / 2
group <- c(rep("W1", n_each), rep("W2", n_each))

W <- simulate(
  f(c(1:n_each, 1:n_each),
    model="bv",
    theta=pi/8, rho=0.5,
    sub_models = list(
      W1 = list(model="ar1", rho=0.6),
      W2 = list(model="ar1", rho=-0.4)
    ),
    group=group,
    noise=list(
      W1 = noise_nig(mu=-2,sigma=1,nu=1),
      W2 = noise_nig(mu=2,sigma=2,nu=0.5)
    )
  )
)
# Here we assume W1 and W2 have positive correlated measurement error
# if they are measured at same index.
# Meaning Y(i) and Y(j) have correlated measurement noise
# if they represent underlying W1(index=k) and W2(index=k)

# Generate covariance matrix for measurement noise
Cov_eps <- matrix(c(1, 0.9, 0.9, 1), nrow=2)
Cov_eps <- Cov_eps %x% diag(n_obs / 2)

# e~N(0, Cov_eps)
L <- t(chol(Cov_eps))
e <- L %*% rnorm(n_obs)

# fixed effects
x1 <- rexp(n_obs)
x2 <- rnorm(n_obs)
feff <- c(-3, 1.5)
# ignore A since here A is Idenitity matrix (well-ordered)
Y <- W + x1 * feff[1] + x2 * feff[2] + as.numeric(e)

out <- ngme(
  Y ~ 0 + x1 + x2 +
    f(c(1:n_each, 1:n_each),
    model="bv",
    name = "bv",
    sub_models = list(W1 = "ar1", W2 = "ar1"),
    noise=list(
      W1 = noise_nig(),
      W2 = noise_nig()
    )
  ),
  group = group,
  family = noise_normal(
    corr_measurement = TRUE,
    index_corr = c(1:n_each, 1:n_each)
  ),
  data = data.frame(Y, x1, x2),
  control_opt = control_opt(
    iterations = 300,
    seed = 7
  )
)
out
```

<!-- ## A spatial Matern example -->

```{r spatial, echo=FALSE, eval=FALSE}
pl01 <- cbind(c(0, 1, 1, 0, 0) * 10, c(0, 0, 1, 1, 0) * 5)
mesh <- fmesher::fm_mesh_2d(
  loc.domain = pl01, cutoff = 0.2,
  max.edge = c(1,10)
)
mesh$n
n_obs <- 300
long <- runif(n_obs, 0, 10)
lat <- runif(n_obs, 0, 5)
group <- c(rep("sal", n_obs/2), rep("temp", n_obs/2))

true_model <- f(
  ~long + lat,
  theta = 0.5, rho = 0.5,
  mesh = mesh,
  model = "bv",
  sub_models = list(
    sal="matern",
    temp="matern"
  ),
  group = group,
  noise = list(sal = noise_nig(
    mu = -2, sigma=1, nu=1
  ), temp = noise_nig(
    mu = 2, sigma=2, nu=0.5
  ))
)
W <- simulate(true_model)
Y <- as.numeric(true_model$A %*% W); Y <- Y + rnorm(length(Y))
data <- data.frame(Y, long, lat)

out <- ngme(
  Y ~ f(
    ~long + lat,
    mesh = mesh,
    model = "bv",
    name = "bv",
    sub_models = list(sal="matern", temp="matern"),
    group = group,
    # debug=T,
    noise = list(sal = noise_nig(), temp = noise_nig())
    # noise = list(sal = noise_normal(), temp = noise_normal())
  ),
  data = data,
  control_opt = control_opt(
    estimation = F,
    iterations = 100,
    n_parallel_chain = 1,
    verbose = F,
    print_check_info = F
  )
)
# out
# str(out$replicates[[1]]$models[[1]]$noise)
# traceplot(out, "bv")
# out$replicates[[1]]$models[[1]]$noise$bv_noises[[2]]$h
```

We can see the estimation results are pretty close to the true value!

Also, sometimes it's tedious to provide to `index_corr` argument to indicate which observations are correlated,
we can use the helper function `compute_index_corr_from_map` to reduce the work.

It can helps to compute the distance (both 1d or 2d distance) given the location we want to use.
If some of them are close enough, then we will correlate them.

```{r compute_index_corr_from_map}
# provide the x,y coordinate (2d locations)
x_coord <- c(1.11, 2.5, 1.12, 2, 1.3, 1.31)
y_coord <- c(1.11, 3.3, 1.11, 2, 1.3, 1.3)
coords <- data.frame(x_coord, y_coord)

# here we can see 2 pairs (1 and 3, 5 and 6) of observations are close enough
compute_index_corr_from_map(coords, eps = 0.1)
```